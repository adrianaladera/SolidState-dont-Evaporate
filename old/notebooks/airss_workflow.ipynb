{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7dabe145-880c-4751-8129-c1adbd06501d",
   "metadata": {},
   "source": [
    "# AIRSS Workflow\n",
    "### Workflow that generates AIRSS metal-chalcogen inorganic structures, charge balances them with H, calculates their energetics, and ranks the structures by their energetics\n",
    "\n",
    "## Import libraries, global variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e4ba0954-2573-4ec5-b6b5-7c09c49c3e2d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import ase\n",
    "import subprocess as sp\n",
    "from ase.io import read, write\n",
    "import ase.neighborlist as nl\n",
    "from ase import Atoms\n",
    "from pymatgen.io.vasp.inputs import Kpoints, Poscar\n",
    "from pymatgen.io.vasp.sets import MPRelaxSet\n",
    "from pymatgen.core import Structure\n",
    "from pymatgen.io.vasp import Vasprun\n",
    "import time\n",
    "import pandas as pd\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# path = \"/Users/adrianaladera/Desktop/MIT/research/MOChAs/airss/AgS_test/\" # local\n",
    "path = \"/pscratch/sd/a/aladera/airss/AgS/var2/\"\n",
    "os.chdir(path)\n",
    "metal, chalc = 'Ag', 'S'\n",
    "seed = metal + chalc\n",
    "path = \"/pscratch/sd/a/aladera/airss/{}/var2/\".format(seed)\n",
    "incar_settings_1 = {\"NELMIN\": 5, \"ALGO\": 'Normal', \"ISPIN\": 1, \"ISMEAR\": 0, \"NSW\": 4, \"ENCUT\": 600, \"EDIFF\" : 1e-4, \"EDIFFG\" : -0.001, \"KPAR\": 1, \"NCORE\": 32, \"SIGMA\" : 0.01, \"NELM\" : 150}  # user custom incar settings\n",
    "incar_settings_2 = {\"NELMIN\": 5, \"ALGO\": 'Normal', \"ISPIN\": 1, \"ISMEAR\": 0, \"NSW\": 20, \"ENCUT\": 700, \"EDIFF\" : 1e-6, \"EDIFFG\" : -0.001, \"KPAR\": 1, \"NCORE\": 32, \"SIGMA\" : 0.01}  # user custom incar settings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7221bff5-1776-4b08-b6c0-8297be4e8099",
   "metadata": {},
   "source": [
    "## Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "423b9421-917a-49c4-9ea1-751f832c39c5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def generate_structs(path, n_structures, seed):\n",
    "    '''Generates structures with AIRSS and converts from .res to .vasp\n",
    "    - path: path to main directory storing all AIRSS generated structures\n",
    "    - n_structures: max number of structures to be generated\n",
    "    - seed: <seed>.cell, source file for generating structures'''\n",
    "    sp.run(\"airss.pl -vasp -build -max {} -seed {}\".format(n_structures, seed), shell=True)\n",
    "    cunt = 0\n",
    "    for file in os.listdir(path):\n",
    "        if \".res\" in file:\n",
    "            struct = read(file)\n",
    "            write(\"{}.vasp\".format(cunt+1), struct)\n",
    "            cunt += 1\n",
    "    sp.run(\"rm *.res\", shell=True)\n",
    "    print(\"{} VASP files generated\".format(cunt))\n",
    "\n",
    "def attach_hydrogens(path, metal, chalcogen, met_chalc_dist, chalc_H_dist, file):\n",
    "    mocha = Structure.from_file(\"{}{}\".format(path,file))\n",
    "    ind_largest_v = np.argmax(mocha.lattice.abc)\n",
    "    positions = []\n",
    "    for atom in range(len(mocha)):\n",
    "        if str(mocha[atom].species) == \"{}1\".format(chalcogen):\n",
    "            pos = np.array(mocha[atom].coords) # coords are Cartesian\n",
    "            neighbors = mocha.get_neighbors(site = mocha[atom], r = met_chalc_dist)\n",
    "            for n in neighbors:\n",
    "                flag = 0\n",
    "                if str(n.species) == \"{}1\".format(metal):\n",
    "                    flag = 1\n",
    "                    if mocha[atom].coords[ind_largest_v] > n.coords[ind_largest_v]: # chalc above metal\n",
    "                        pos[ind_largest_v] += chalc_H_dist  # add H above chalc\n",
    "                    elif mocha[atom].coords[ind_largest_v] < n.coords[ind_largest_v]: # chalc below metal\n",
    "                        pos[ind_largest_v] -= chalc_H_dist  # add H below chalc\n",
    "                if flag:\n",
    "                    break\n",
    "            positions.append(pos)\n",
    "    for p in positions:\n",
    "        mocha.append('H', p, coords_are_cartesian=True)\n",
    "    poscar = Poscar(mocha)\n",
    "    poscar.write_file(\"{}{}{}H-{}\".format(path, metal, chalcogen, file))\n",
    "\n",
    "def create_job_dirs(path, seed): \n",
    "    '''\n",
    "    - relax 4 x NSW = 4\n",
    "    - then relax NSW = 20, get energies but no calculations (see Aria's notebook)\n",
    "    - pick a subset based on energies and how many times each structures are repeated (based on space group)\n",
    "    - relax subset until convergence + run static; final structures\n",
    "    '''\n",
    "    job_dirs = []\n",
    "    for file in os.listdir(path):\n",
    "        if \".vasp\" in file and seed in file:\n",
    "            sp.run(\"mkdir {} \".format(file[:-5]), shell=True)\n",
    "            job_dirs.append(str(file[:-5]))\n",
    "            sp.run(\"cp {} {}/POSCAR\".format(file, file[:-5]), shell=True) # POSCAR\n",
    "            sp.run(\"cp {} {}/POSCAR_0\".format(file, file[:-5]), shell=True) # POSCAR\n",
    "            sp.run(\"pot\".format(file[:-5]), shell=True) # POINTS\n",
    "            structure = Structure.from_file(\"{}/POSCAR\".format(file[:-5])) # cp POSCAR, make KPOINTS, INCAR\n",
    "            relax = MPRelaxSet(structure, user_incar_settings=incar_settings_1)\n",
    "            relax.write_input(\"{}\".format(file[:-5]), potcar_spec=False)\n",
    "            sp.run(\"python pot.py {}/POSCAR\".format(file[:-5]), shell=True)\n",
    "        elif \".vasp\" in file and seed not in file:\n",
    "            sp.run(\"rm {}\".format(file), shell=True)\n",
    "    return job_dirs\n",
    "\n",
    "def is_converged(path, seed, ionic_steps):\n",
    "    '''ionic_steps - number of steps (AIRSS needs only 3 or 4 steps, considered \"converged\")'''\n",
    "    if os.path.isfile(\"{}/job.out\".format(path)):\n",
    "        sp.run(\"grep \\\"{} F=\\\" {}/job.out | awk '{}print $1{}' > {}/ionic_steps\".format(ionic_steps, path, '{','}', path), shell=True)\n",
    "        with open(\"{}/ionic_steps\".format(path), \"r\") as f:\n",
    "            if str(ionic_steps) in f.read():\n",
    "                return 1\n",
    "            else:\n",
    "                return 0\n",
    "        \n",
    "def is_running(path, dir_name):\n",
    "    '''Checks to see if a job is currently running in a directory. If so, the job is not overridden'''\n",
    "    # os.chdir(path)\n",
    "    os.system(\"squeue -u aladera --format \\\"%Z\\\" > running_jobs\")\n",
    "    with open(\"running_jobs\", 'r') as f:  \n",
    "        if dir_name in f.read():\n",
    "            return 1\n",
    "        else:\n",
    "            return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54b9167e-75d8-4787-994d-279a2ebb7bcc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "860ebef4",
   "metadata": {},
   "source": [
    "## Main code that calls all the functions\n",
    "### Do not run until doing another test on NERSC!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "11a3c979-49f1-4b9b-b361-80fea3095c98",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 VASP files generated\n"
     ]
    }
   ],
   "source": [
    "generate_structs(path, 10, seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e1ff3f72-5645-4cb0-8810-9f394a493b7d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 VASP files generated\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/bin/sh: pot: command not found\n",
      "python: can't open file 'pot.py': [Errno 2] No such file or directory\n",
      "/bin/sh: pot: command not found\n",
      "python: can't open file 'pot.py': [Errno 2] No such file or directory\n",
      "/bin/sh: pot: command not found\n",
      "python: can't open file 'pot.py': [Errno 2] No such file or directory\n",
      "/bin/sh: pot: command not found\n",
      "python: can't open file 'pot.py': [Errno 2] No such file or directory\n",
      "/bin/sh: pot: command not found\n",
      "python: can't open file 'pot.py': [Errno 2] No such file or directory\n",
      "/bin/sh: pot: command not found\n",
      "python: can't open file 'pot.py': [Errno 2] No such file or directory\n",
      "/bin/sh: pot: command not found\n",
      "python: can't open file 'pot.py': [Errno 2] No such file or directory\n",
      "/bin/sh: pot: command not found\n",
      "python: can't open file 'pot.py': [Errno 2] No such file or directory\n",
      "/bin/sh: pot: command not found\n",
      "python: can't open file 'pot.py': [Errno 2] No such file or directory\n",
      "/bin/sh: pot: command not found\n",
      "python: can't open file 'pot.py': [Errno 2] No such file or directory\n"
     ]
    }
   ],
   "source": [
    "generate_structs(path, 10, seed)\n",
    "\n",
    "# for each structure, take generated structures and attach H, then write to new vasp file\n",
    "for file in os.listdir(path):\n",
    "    if seed not in file and \".vasp\" in file:\n",
    "        attach_hydrogens(path, metal, chalc, 3.0, 1.3, file)\n",
    "        sp.run(\"rm {}\".format(file), shell=True)\n",
    "job_dirs = create_job_dirs(path, seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3c765c78-1b21-4ccf-9ada-5a2f091cbe52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 AgS jobs submitted\n"
     ]
    }
   ],
   "source": [
    "# run the calculations\n",
    "cunt = 0\n",
    "for j in job_dirs:\n",
    "    if os.path.isdir(\"{}{}\".format(path, j)):\n",
    "        os.chdir(\"{}{}\".format(path, j))\n",
    "        os.system(\"vrun 1 32 4 {} > submit_note\".format(j));\n",
    "        os.chdir(path)\n",
    "        cunt += 1\n",
    "print(\"{} {} jobs submitted\".format(cunt, seed))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1c12070-14d3-4254-89fe-0bf3c0bfcdec",
   "metadata": {},
   "source": [
    "### Only do this for the first round of convergence 4x4\n",
    "Will overwrite with new CSV of other converged structures otherwise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "787e0049-e166-44b2-975b-5e6e47dfbc7a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converged: 698, Unconverged: 302\n"
     ]
    }
   ],
   "source": [
    "converged = []\n",
    "unconverged = []\n",
    "for i in os.listdir(path):\n",
    "    if os.path.isdir(i) and seed in i:\n",
    "        if is_converged(\"{}{}\".format(path, i), seed, 4):\n",
    "            converged.append(i)\n",
    "        else:\n",
    "            unconverged.append(i)\n",
    "            \n",
    "print(\"Converged: {}, Unconverged: {}\".format(len(converged), len(unconverged)))\n",
    "# dfc = pd.DataFrame({\"converged\":converged})\n",
    "# dfu = pd.DataFrame({\"unconverged\":unconverged})\n",
    "# dfc.to_csv(\"{}1st_round_converged.csv\".format(path), index=False)\n",
    "# dfu.to_csv(\"{}1st_round_unconverged.csv\".format(path), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "009008b3-6331-4762-b54e-317e1d26cb2a",
   "metadata": {},
   "source": [
    "### Checking how many structures are in the queue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2a514eef-8420-404b-b746-ceafb36e685a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "85 structures already running, 856 structures queued\n"
     ]
    }
   ],
   "source": [
    "# cunt = 1\n",
    "# while cunt < 10:\n",
    "    # time.sleep(14400)\n",
    "running, queued = 0,0\n",
    "# dtf = pd.read_csv(\"{}1st_round_converged.csv\".format(path))\n",
    "# converged = dtf[\"converged\"]\n",
    "for i in range(len(converged)):\n",
    "    # os.chdir(path + converged[i])\n",
    "    if is_running(path, converged[i]):\n",
    "        running += 1\n",
    "    else:\n",
    "        os.chdir(path + converged[i])\n",
    "        queued += 1\n",
    "        os.system(\"cp CONTCAR POSCAR\")\n",
    "        for j in range(1,5):\n",
    "            if not os.path.exists(\"POSCAR_{}\".format(j)):\n",
    "                os.system(\"cp CONTCAR POSCAR_{}\".format(j))\n",
    "                break\n",
    "        os.system(\"vrun 1 32 5 {} > submit_note\".format(converged[i]))\n",
    "        os.chdir(path)\n",
    "print(\"{} structures already running, {} structures queued\".format(running, queued))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "019fb88f-bc18-43c3-bb0b-0bd405fa4b1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now we check the convergence again and run the incar_settings_2\n",
    "converged_calcs, unconverged_calcs = check_convergence(path, seed, 4)\n",
    "\n",
    "for i in range(len(converged_calcs)):\n",
    "    os.chdir(path + converged_calcs[i])\n",
    "    os.system(\"cp CONTCAR POSCAR_4\")\n",
    "    relax_2 = MPRelaxSet.from_prev_calc(\".\", user_incar_settings=incar_settings_2)\n",
    "    relax_2.write_input(\"{}\".format(converged_calcs[i]), potcar_spec=True)\n",
    "\n",
    "# We need to get the energies of the structures that are converged and rank them from lowest to highest\n",
    "\n",
    "converged_calcs = check_convergence(PATH, 20, structures)\n",
    "\n",
    "for i in range(len(converged_calcs)):\n",
    "    energies = []\n",
    "    os.chdir(PATH + f\"struc_{converged_calcs[i]}\" + f\"r2_struc_{converged_calcs[i]}\") # need to change this to the correct path\n",
    "    energy = Vasprun(\"vasprun.xml\").final_energy #write energy of each structure\n",
    "    energies.append(energy)\n",
    "\n",
    "# now match the energy list and the structure name as a dataframe and sort the energies from lowest to highest\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame(list(zip(converged_calcs, energies)), columns = [\"structure\", \"energy\"])\n",
    "df.sort_values(by=[\"energy\"], inplace=True)\n",
    "#more proper relaxations after analysis"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv-jupyter",
   "language": "python",
   "name": "myenv-jupyter"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
